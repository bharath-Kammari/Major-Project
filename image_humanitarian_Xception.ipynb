{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "#from keras.utils import load_img,img_to_array\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('task_humanitarian_text_img_train.csv')\n",
    "test_data = pd.read_csv('task_humanitarian_text_img_test.csv')\n",
    "val_data = pd.read_csv('task_humanitarian_text_img_dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_image=[]\n",
    "Y1_image=[]\n",
    "X2_image=[]\n",
    "Y2_image=[]\n",
    "X3_image=[]\n",
    "Y3_image=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,13608):\n",
    "    if train_data['label_text'][i]==train_data['label_image'][i]:\n",
    "        X1_image.append(train_data['image'][i])\n",
    "        Y1_image.append(train_data['label_image'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2237):\n",
    "    if test_data['label_text'][i]==test_data['label_image'][i]:\n",
    "        X2_image.append(test_data['image'][i])\n",
    "        Y2_image.append(test_data['label_image'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2237):\n",
    "    if val_data['label_text'][i]==val_data['label_image'][i]:\n",
    "        X3_image.append(val_data['image'][i])\n",
    "        Y3_image.append(val_data['label_image'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 100, 100\n",
    "num_classes = 8\n",
    "img_train = []\n",
    "img_test = []\n",
    "img_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in X1_image:\n",
    "    img = load_img( filename, target_size=(img_width, img_height))\n",
    "    img_array = img_to_array(img)\n",
    "    img_train.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in X2_image:\n",
    "    img = load_img( filename, target_size=(img_width, img_height))\n",
    "    img_array = img_to_array(img)\n",
    "    img_test.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in X3_image:\n",
    "    img = load_img( filename, target_size=(img_width, img_height))\n",
    "    img_array = img_to_array(img)\n",
    "    img_val.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = np.array(img_train)\n",
    "img_test = np.array(img_test)\n",
    "img_val = np.array(img_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = img_train / 255.0\n",
    "img_test = img_test / 255.0\n",
    "img_val = img_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempTrain=[]\n",
    "tempTest=[]\n",
    "tempVal=[]\n",
    "\n",
    "for i in range(0, len(Y1_image)):\n",
    "    if train_data['label'][i] == 'affected_individuals':\n",
    "        tempTrain.append(0)\n",
    "    elif train_data['label'][i] == 'infrastructure_and_utility_damage':\n",
    "        tempTrain.append(1)\n",
    "    elif train_data['label'][i] == 'injured_or_dead_people':\n",
    "        tempTrain.append(2)\n",
    "    elif train_data['label'][i] == 'missing_or_found_people':\n",
    "        tempTrain.append(3)\n",
    "    elif train_data['label'][i] == 'not_humanitarian':\n",
    "        tempTrain.append(4)\n",
    "    elif train_data['label'][i] == 'other_relevant_information':\n",
    "        tempTrain.append(5)\n",
    "    elif train_data['label'][i] == 'rescue_volunteering_or_donation_effort':\n",
    "        tempTrain.append(6)\n",
    "    elif train_data['label'][i] == 'vehicle_damage':\n",
    "        tempTrain.append(7)\n",
    "\n",
    "for i in range(0, len(Y2_image)):\n",
    "    if test_data['label'][i] == 'affected_individuals':\n",
    "        tempTest.append(0)\n",
    "    elif test_data['label'][i] == 'infrastructure_and_utility_damage':\n",
    "        tempTest.append(1)\n",
    "    elif test_data['label'][i] == 'injured_or_dead_people':\n",
    "        tempTest.append(2)\n",
    "    elif test_data['label'][i] == 'missing_or_found_people':\n",
    "        tempTest.append(3)\n",
    "    elif test_data['label'][i] == 'not_humanitarian':\n",
    "        tempTest.append(4)\n",
    "    elif test_data['label'][i] == 'other_relevant_information':\n",
    "        tempTest.append(5)\n",
    "    elif test_data['label'][i] == 'rescue_volunteering_or_donation_effort':\n",
    "        tempTest.append(6)\n",
    "    elif test_data['label'][i] == 'vehicle_damage':\n",
    "        tempTest.append(7)\n",
    "\n",
    "for i in range(0, len(Y3_image)):\n",
    "    if val_data['label'][i] == 'affected_individuals':\n",
    "        tempVal.append(0)\n",
    "    elif val_data['label'][i] == 'infrastructure_and_utility_damage':\n",
    "        tempVal.append(1)\n",
    "    elif val_data['label'][i] == 'injured_or_dead_people':\n",
    "        tempVal.append(2)\n",
    "    elif val_data['label'][i] == 'missing_or_found_people':\n",
    "        tempVal.append(3)\n",
    "    elif val_data['label'][i] == 'not_humanitarian':\n",
    "        tempVal.append(4)\n",
    "    elif val_data['label'][i] == 'other_relevant_information':\n",
    "        tempVal.append(5)\n",
    "    elif val_data['label'][i] == 'rescue_volunteering_or_donation_effort':\n",
    "        tempVal.append(6)\n",
    "    elif val_data['label'][i] == 'vehicle_damage':\n",
    "        tempVal.append(7)\n",
    "        \n",
    "labels_train = tempTrain\n",
    "labels_test = tempTest\n",
    "labels_val = tempVal\n",
    "Y_train = to_categorical(labels_train, num_classes=num_classes)\n",
    "Y_test = to_categorical(labels_test, num_classes=num_classes)\n",
    "Y_val = to_categorical(labels_val, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Xception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_input = Input(shape=(img_width, img_height, 3))\n",
    "xception_model = Xception(weights='imagenet', include_top=False, input_tensor=xception_input, pooling='max')\n",
    "xception_output = Dense(num_classes, activation='softmax')(xception_model.output)\n",
    "xception_model = Model(inputs=xception_input, outputs=xception_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_model.fit(img_train, Y_train, batch_size=40, epochs=10, validation_data=(img_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = xception_model.evaluate(img_test, Y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xception_model.predict(img_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels from one-hot encoding to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_classes = np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test_classes, y_pred_classes)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
