{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from keras.applications import ResNet50\n", "from sklearn.metrics import accuracy_score,precision_score,f1_score\n", "from sklearn.model_selection import train_test_split\n", "from keras.preprocessing.text import Tokenizer\n", "from keras.layers import Dense, Input, LSTM, concatenate, Embedding\n", "from keras.models import Model\n", "from keras.utils import img_to_array, load_img\n", "from keras.utils import pad_sequences\n", "from keras.utils import to_categorical"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load text data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data = pd.read_csv('task_informative_text_img_train.csv')\n", "test_data = pd.read_csv('task_informative_text_img_test.csv')\n", "val_data = pd.read_csv('task_informative_text_img_dev.csv')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X1_text=[]\n", "Y1_text=[]\n", "X2_text=[]\n", "Y2_text=[]\n", "X3_text=[]\n", "Y3_text=[]\n", "# train\n", "for i in range(0,13608):\n", "    if train_data['label_text'][i]==train_data['label_image'][i]:\n", "        X1_text.append(train_data['tweet_text'][i])\n", "        Y1_text.append(train_data['label_text'][i])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0,2237):\n", "    if test_data['label_text'][i]==test_data['label_image'][i]:\n", "        X2_text.append(test_data['tweet_text'][i])\n", "        Y2_text.append(test_data['label_text'][i])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0,2237):\n", "    if val_data['label_text'][i]==val_data['label_image'][i]:\n", "        X3_text.append(val_data['tweet_text'][i])\n", "        Y3_text.append(val_data['label_text'][i])\n", "# Tokenize text data\n", "max_words = 10000\n", "max_len = 100\n", "tokenizer = Tokenizer(num_words=max_words)\n", "tokenizer.fit_on_texts(X1_text)\n", "sequences_train = tokenizer.texts_to_sequences(X1_text)\n", "sequences_test = tokenizer.texts_to_sequences(X2_text)\n", "sequences_val = tokenizer.texts_to_sequences(X3_text)\n", "x_train = pad_sequences(sequences_train, maxlen=max_len)\n", "x_test = pad_sequences(sequences_test, maxlen=max_len)\n", "x_val = pad_sequences(sequences_val, maxlen=max_len)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X1_image=[]\n", "Y1_image=[]\n", "X2_image=[]\n", "Y2_image=[]\n", "X3_image=[]\n", "Y3_image=[]\n", "# train\n", "for i in range(0,13608):\n", "    if train_data['label_text'][i]==train_data['label_image'][i]:\n", "        X1_image.append(train_data['image'][i])\n", "        Y1_image.append(train_data['label_image'][i])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0,2237):\n", "    if test_data['label_text'][i]==test_data['label_image'][i]:\n", "        X2_image.append(test_data['image'][i])\n", "        Y2_image.append(test_data['label_image'][i])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0,2237):\n", "    if val_data['label_text'][i]==val_data['label_image'][i]:\n", "        X3_image.append(val_data['image'][i])\n", "        Y3_image.append(val_data['label_image'][i])\n", "# Load image data\n", "img_width, img_height = 100, 100\n", "num_classes = 2\n", "img_train = []\n", "img_test = []\n", "img_val = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filename in X1_image:\n", "    img = load_img( filename, target_size=(img_width, img_height))\n", "    img_array = img_to_array(img)\n", "    img_train.append(img_array)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filename in X2_image:\n", "    img = load_img( filename, target_size=(img_width, img_height))\n", "    img_array = img_to_array(img)\n", "    img_test.append(img_array)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filename in X3_image:\n", "    img = load_img( filename, target_size=(img_width, img_height))\n", "    img_array = img_to_array(img)\n", "    img_val.append(img_array)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img_train = np.array(img_train)\n", "img_test = np.array(img_test)\n", "img_val = np.array(img_val)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define LSTM model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lstm_input = Input(shape=(max_len,))\n", "embedding_layer = Embedding(max_words, 128)(lstm_input)\n", "lstm_layer = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n", "lstm_output = Dense(num_classes, activation='sigmoid')(lstm_layer)\n", "lstm_model = Model(inputs=lstm_input, outputs=lstm_output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define resnet model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["resnet_input = Input(shape=(img_width, img_height, 3))\n", "resnet_model = ResNet50(weights='imagenet', include_top=False, input_tensor=resnet_input, pooling='max')\n", "resnet_output = Dense(num_classes, activation='sigmoid')(resnet_model.output)\n", "resnet_model = Model(inputs=resnet_input, outputs=resnet_output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Combine LSTM and resnet models with intermediate fusion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(np.shape(lstm_model.output))\n", "print(np.shape(resnet_model.output))\n", "combined_input = concatenate([lstm_model.output, resnet_model.output])\n", "fusion_output = Dense(num_classes, activation='sigmoid')(combined_input)\n", "fusion_model = Model(inputs=[lstm_model.input, resnet_model.input], outputs=fusion_output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compile the fusion model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fusion_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the fusion model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tempTr=[]\n", "tempTe=[]\n", "tempDe=[]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0, len(Y1_text)):\n", "    if Y1_text[i] == 'informative':\n", "        tempTr.append(0)\n", "    else:\n", "        tempTr.append(1)\n", "for i in range(0, len(Y2_text)):\n", "    if Y2_text[i] == 'informative':\n", "        tempTe.append(0)\n", "    else:\n", "        tempTe.append(1)\n", "for i in range(0, len(Y3_text)):\n", "    if Y3_text[i] == 'informative':\n", "        tempDe.append(0)\n", "    else:\n", "        tempDe.append(1)\n", "labels_train = tempTr\n", "labels_test = tempTe\n", "labels_val = tempDe\n", "y_train = to_categorical(labels_train, num_classes=num_classes)\n", "y_test = to_categorical(labels_test, num_classes=num_classes)\n", "y_val = to_categorical(labels_val, num_classes=num_classes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["history = fusion_model.fit([x_train, img_train], y_train,\n", "                           epochs=15, batch_size=40,\n", "                           validation_data=([x_val, img_val], y_val))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate the fusion model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["score = fusion_model.evaluate([x_test, img_test], y_test, verbose=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print accuracy, precision, and F1 score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = fusion_model.predict([x_test, img_test])\n", "y_pred = np.argmax(y_pred, axis=1)\n", "y_test = np.argmax(y_test, axis=1)\n", "acc = accuracy_score(y_test, y_pred)\n", "precision = precision_score(y_test, y_pred, average='weighted')\n", "f1 = f1_score(y_test, y_pred, average='weighted')\n", "print(\"Accuracy: {:.2f}%\".format(acc*100))\n", "print(\"Precision: {:.2f}%\".format(precision*100))\n", "print(\"F1 Score: {:.2f}%\".format(f1*100))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}