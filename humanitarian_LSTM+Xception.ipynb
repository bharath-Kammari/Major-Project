{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from sklearn.metrics import accuracy_score,precision_score,f1_score\n", "from sklearn.model_selection import train_test_split\n", "from keras.applications.xception import Xception\n", "from keras.preprocessing.text import Tokenizer\n", "from keras.layers import Dense, Input, LSTM, concatenate, Embedding\n", "from keras.models import Model\n", "from keras.utils import img_to_array, load_img\n", "from keras.utils import pad_sequences\n", "from keras.utils import to_categorical"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load text data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_data = pd.read_csv('task_humanitarian_text_img_train.csv')\n", "test_data = pd.read_csv('task_humanitarian_text_img_test.csv')\n", "val_data = pd.read_csv('task_humanitarian_text_img_dev.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Tokenize text data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["max_words = 10000\n", "max_len = 100\n", "tokenizer = Tokenizer(num_words=max_words)\n", "tokenizer.fit_on_texts(train_data['tweet_text'])\n", "sequences_train = tokenizer.texts_to_sequences(train_data['tweet_text'])\n", "sequences_test = tokenizer.texts_to_sequences(test_data['tweet_text'])\n", "sequences_val = tokenizer.texts_to_sequences(val_data['tweet_text'])\n", "x_train = pad_sequences(sequences_train, maxlen=max_len)\n", "x_test = pad_sequences(sequences_test, maxlen=max_len)\n", "x_val = pad_sequences(sequences_val, maxlen=max_len)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load image data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img_width, img_height = 100, 100\n", "num_classes = 8\n", "img_train = []\n", "img_test = []\n", "img_val = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filename in train_data['image']:\n", "    img = load_img( filename, target_size=(img_width, img_height))\n", "    img_array = img_to_array(img)\n", "    img_train.append(img_array)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filename in test_data['image']:\n", "    img = load_img( filename, target_size=(img_width, img_height))\n", "    img_array = img_to_array(img)\n", "    img_test.append(img_array)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for filename in val_data['image']:\n", "    img = load_img( filename, target_size=(img_width, img_height))\n", "    img_array = img_to_array(img)\n", "    img_val.append(img_array)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img_train = np.array(img_train)\n", "img_test = np.array(img_test)\n", "img_val = np.array(img_val)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define LSTM model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lstm_input = Input(shape=(max_len,))\n", "embedding_layer = Embedding(max_words, 128)(lstm_input)\n", "lstm_layer = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n", "lstm_output = Dense(num_classes, activation='softmax')(lstm_layer)\n", "lstm_model = Model(inputs=lstm_input, outputs=lstm_output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define Xception model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["xception_input = Input(shape=(img_width, img_height, 3))\n", "xception_model = Xception(weights='imagenet', include_top=False, input_tensor=xception_input, pooling='max')\n", "xception_output = Dense(num_classes, activation='softmax')(xception_model.output)\n", "xception_model = Model(inputs=xception_input, outputs=xception_output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Combine LSTM and Xception models with intermediate fusion"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["combined_input = concatenate([lstm_model.output, xception_model.output])\n", "fusion_output = Dense(num_classes, activation='softmax')(combined_input)\n", "fusion_model = Model(inputs=[lstm_model.input, xception_model.input], outputs=fusion_output)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compile the fusion model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fusion_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Train the fusion model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tempTrain=[]\n", "tempTest=[]\n", "tempVal=[]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0, 13608):\n", "    if train_data['label'][i] == 'affected_individuals':\n", "        tempTrain.append(0)\n", "    elif train_data['label'][i] == 'infrastructure_and_utility_damage':\n", "        tempTrain.append(1)\n", "    elif train_data['label'][i] == 'injured_or_dead_people':\n", "        tempTrain.append(2)\n", "    elif train_data['label'][i] == 'missing_or_found_people':\n", "        tempTrain.append(3)\n", "    elif train_data['label'][i] == 'not_humanitarian':\n", "        tempTrain.append(4)\n", "    elif train_data['label'][i] == 'other_relevant_information':\n", "        tempTrain.append(5)\n", "    elif train_data['label'][i] == 'rescue_volunteering_or_donation_effort':\n", "        tempTrain.append(6)\n", "    elif train_data['label'][i] == 'vehicle_damage':\n", "        tempTrain.append(7)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0, 2237):\n", "    if test_data['label'][i] == 'affected_individuals':\n", "        tempTest.append(0)\n", "    elif test_data['label'][i] == 'infrastructure_and_utility_damage':\n", "        tempTest.append(1)\n", "    elif test_data['label'][i] == 'injured_or_dead_people':\n", "        tempTest.append(2)\n", "    elif test_data['label'][i] == 'missing_or_found_people':\n", "        tempTest.append(3)\n", "    elif test_data['label'][i] == 'not_humanitarian':\n", "        tempTest.append(4)\n", "    elif test_data['label'][i] == 'other_relevant_information':\n", "        tempTest.append(5)\n", "    elif test_data['label'][i] == 'rescue_volunteering_or_donation_effort':\n", "        tempTest.append(6)\n", "    elif test_data['label'][i] == 'vehicle_damage':\n", "        tempTest.append(7)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(0, 2237):\n", "    if val_data['label'][i] == 'affected_individuals':\n", "        tempVal.append(0)\n", "    elif val_data['label'][i] == 'infrastructure_and_utility_damage':\n", "        tempVal.append(1)\n", "    elif val_data['label'][i] == 'injured_or_dead_people':\n", "        tempVal.append(2)\n", "    elif val_data['label'][i] == 'missing_or_found_people':\n", "        tempVal.append(3)\n", "    elif val_data['label'][i] == 'not_humanitarian':\n", "        tempVal.append(4)\n", "    elif val_data['label'][i] == 'other_relevant_information':\n", "        tempVal.append(5)\n", "    elif val_data['label'][i] == 'rescue_volunteering_or_donation_effort':\n", "        tempVal.append(6)\n", "    elif val_data['label'][i] == 'vehicle_damage':\n", "        tempVal.append(7)\n", "        \n", "labels_train = tempTrain\n", "labels_test = tempTest\n", "labels_val = tempVal\n", "y_train = to_categorical(labels_train, num_classes=num_classes)\n", "y_test = to_categorical(labels_test, num_classes=num_classes)\n", "y_val = to_categorical(labels_val, num_classes=num_classes)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["history = fusion_model.fit([x_train, img_train], y_train,\n", "                           epochs=10, batch_size=32,\n", "                           validation_data=([x_val, img_val], y_val))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Evaluate the fusion model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["score = fusion_model.evaluate([x_test, img_test], y_test, verbose=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print accuracy, precision, and F1 score"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = fusion_model.predict([x_test, img_test])\n", "y_pred = np.argmax(y_pred, axis=1)\n", "y_test = np.argmax(y_test, axis=1)\n", "acc = accuracy_score(y_test, y_pred)\n", "precision = precision_score(y_test, y_pred, average='weighted')\n", "f1 = f1_score(y_test, y_pred, average='weighted')\n", "print(\"Accuracy: {:.2f}%\".format(acc*100))\n", "print(\"Precision: {:.2f}%\".format(precision*100))\n", "print(\"F1 Score: {:.2f}%\".format(f1*100))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}